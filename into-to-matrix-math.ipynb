{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "into-to-matrix-math.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ncssmmlclub/Lectures/blob/master/into-to-matrix-math.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS3ARmxLuBUT"
      },
      "source": [
        "# Introduction to Matrix and Vector Mathematics\n",
        "\n",
        "Today, we'll be discussing how vectors and matrices work!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQmDg507uBUU"
      },
      "source": [
        "## 1.1 What even are Vectors and Matrices?\n",
        "\n",
        "**_First of all, what is a vector?_**\n",
        "\n",
        "A vector is quantity with a direction and a magnitude (as seen pictured below)\n",
        "\n",
        "<img src=\"https://i.ibb.co/JnG1FWB/vector.png\" alt=\"vector\" border=\"0\">\n",
        "\n",
        "In machine learning, they can represent a large variety of data including parameter spaces, coordinates, as well as changes to the aforementioned data.\n",
        "\n",
        "Note that vectors don't have a specific start position. Sometimes, when discussing coordinates we will use the vector to represent a position as a certain direction and magnitude from the origin, but the vector itself does not specify an origin.\n",
        "\n",
        "When we discuss vectors, we typically refer to column vectors, which are also $n \\times 1$ matrices and are represented as such:\n",
        "\n",
        "$$ \\vec{v} = \\begin{bmatrix}a\\\\b\\\\c\\\\d\\end{bmatrix}$$\n",
        "\n",
        "where $a$, $b$, $c$, and $d$ are components of the vector (and matrix).\n",
        "\n",
        "Sometimes, however, we will use row vectors, which are $1 \\times n$ matrices and are the **transpose** of the corresponding column vector and are represented like so:\n",
        "\n",
        "$$ \\vec{v}^\\top = \\begin{bmatrix}a & b & c & d\\end{bmatrix}$$\n",
        "\n",
        "In literature, vectors are often lowercase and denoted in boldface ($\\mathbf{v}$) or with an arrow ($\\vec{v}$).\n",
        "\n",
        "**_Secondly, what is a matrix?_**\n",
        "\n",
        "A matrix is a rectangular grid of numbers, and are usually used to represent **transformations** and parameters spaces, (as well as changes to that data).\n",
        "\n",
        "Matrices are often denoted with boldface uppercase characters as such:\n",
        "\n",
        "$$\\mathbf{A} = \\begin{bmatrix}A_{11} & A_{12} & A_{13}\\\\ A_{21} & A_{22} & A_{23}\\\\ A_{31} & A_{32} & A_{33} \\end{bmatrix}$$\n",
        "\n",
        "In this matrix $A_{ij}$ (where $i$ and $j$ are indices from 1 to 3) represents the components of the matrix. Notice that unlike Python, we are indexing from 1.\n",
        "\n",
        "Matrices come in all shapes and sizes and we can represent its shape by the number of rows and columns ($m$ rows and $n$ columns = $m \\times n$ matrix)\n",
        "\n",
        "For example, $\\mathbf{A}$ is a $3 \\times 3$ matrix.\n",
        "\n",
        "##### MiniQuiz\n",
        "\n",
        "1. What is the size of this matrix?\n",
        "\n",
        "$$\\mathbf{C} = \\begin{bmatrix}1 & 0 & -4 & 10 & 0.2 & 6 & 2+2i \\\\ 2 & 4 & 2.6 & 0.8 & -4.2 & \\sqrt[4]{-1} & 1.5\\\\ 3 & 10 & -\\pi & e & 2.1 & \\alpha & -\\sqrt{17}/5\\\\ 5 & 8 & 2 & 1 & \\pi^{-1} & \\sqrt{2} & 1.1\\end{bmatrix}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDXp04hKuBUV"
      },
      "source": [
        "# 1.2 What can I do with Vectors and Matrices?\n",
        "\n",
        "Just like we can with numbers and variables, we can combine vectors and matrices in fun ways to do interesting things.\n",
        "\n",
        "In regular arithmetics, we can add, subtract, multiply numbers. Can we do the same with matrices and vectors?\n",
        "\n",
        "Indeed we can, but we have certain constraints.\n",
        "\n",
        "#### Addition\n",
        "\n",
        "**Vectors**\n",
        "\n",
        "To add vectors, they both need to be of the same size. If $\\vec{a}$ and $\\vec{b}$ are of size $4 \\times 1$ and $5 \\times 1$, you cannot add them together, because it simply makes no sense.\n",
        "\n",
        "However, if the are of the same size, addition is relatively straightforward:\n",
        "\n",
        "$$ \\vec{a} = \\begin{bmatrix}a_x\\\\a_y\\\\a_z\\end{bmatrix}$$\n",
        "\n",
        "$$ \\vec{b} = \\begin{bmatrix}b_x\\\\b_y\\\\b_z\\end{bmatrix}$$\n",
        "\n",
        "$$ \\vec{a} + \\vec{b} = \\begin{bmatrix}a_x+b_x\\\\a_y+b_y\\\\a_z+b_z\\end{bmatrix}$$\n",
        "\n",
        "Tada! It was that simple!\n",
        "\n",
        "But what does that mean geometrically?\n",
        "\n",
        "Well, if vectors represent directions and magnitudes, the sum of two vectors tells you the total direction and magnitude travelled if you travel along the first vector and then the second vector.\n",
        "\n",
        "<img src=\"https://i.ibb.co/1GkFWyZ/addvec.png\" alt=\"addvec\" border=\"0\">\n",
        "\n",
        "Let's try matrices now!\n",
        "\n",
        "**Matrices**\n",
        "\n",
        "Just like vectors, matrices must be of equivalent sizes to sum them together.\n",
        "\n",
        "$$\\mathbf{A} = \\begin{bmatrix}A_{11} & A_{12}\\\\ A_{21} & A_{22}\\end{bmatrix}$$\n",
        "\n",
        "$$\\mathbf{B} = \\begin{bmatrix}B_{11} & B_{12}\\\\ B_{21} & B_{22}\\end{bmatrix}$$\n",
        "\n",
        "$$\\mathbf{A} + \\mathbf{B} = \\begin{bmatrix}A_{11} + B_{11} & A_{12} + B_{12}\\\\ A_{21} + B_{21} & A_{22} + B_{22}\\end{bmatrix}$$\n",
        "\n",
        "\n",
        "##### MiniQuiz\n",
        "\n",
        "If we have a row vector $\\begin{bmatrix}1 & 2 & 3\\end{bmatrix}$ and another row vector $\\begin{bmatrix}-7 & 6 & 2 & 8\\end{bmatrix}$, what is their sum?\n",
        "\n",
        "What about the sum of row vector $\\begin{bmatrix}8 & -9 & 2 & 16\\end{bmatrix}$ and $\\begin{bmatrix}-7 & 6 & 2 & 8\\end{bmatrix}$?\n",
        "\n",
        "#### Subtraction\n",
        "\n",
        "Subtraction is the exact same as addition except we negate the second operand's components.\n",
        "\n",
        "So, for vectors:\n",
        "\n",
        "$$ \\vec{a} - \\vec{b} = \\begin{bmatrix}a_x-b_x\\\\a_y-b_y\\\\a_z-b_z\\end{bmatrix}$$\n",
        "\n",
        "And for matrices:\n",
        "\n",
        "$$\\mathbf{A} - \\mathbf{B} = \\begin{bmatrix}A_{11} - B_{11} & A_{12} - B_{12}\\\\ A_{21} - B_{21} & A_{22} - B_{22}\\end{bmatrix}$$\n",
        "\n",
        "For vectors, this can be seen geometrically as finding the vector displacement from the one position to another.\n",
        "\n",
        "<img src=\"https://i.ibb.co/1GkFWyZ/addvec.png\" alt=\"addvec\" border=\"0\">\n",
        "\n",
        "#### Multiplication\n",
        "\n",
        "Aha! For vectors and matrices, multiplication is defined in SOOOOO MANY WAYS!\n",
        "\n",
        "Let's start off with **scalar multiplication**.\n",
        "\n",
        "Firstly, what is a scalar?\n",
        "\n",
        "A scalar is just a regular number (no direction or magnitude).\n",
        "\n",
        "So, let's scale!\n",
        "\n",
        "For vectors:\n",
        "$ \\lambda\\vec{a} = \\begin{bmatrix}{\\lambda a_x} \\\\ {\\lambda a_y} \\\\ {\\lambda a_z} \\end{bmatrix}$\n",
        "For matrices:\n",
        "$$\\lambda\\mathbf{A} = \\begin{bmatrix} \\lambda A_{11} & \\lambda A_{12}\\\\ \\lambda A_{21} & \\lambda A_{22}\\end{bmatrix}$$\n",
        "\n",
        "Remember, $\\lambda$ is a scalar, not a vector or matrix.\n",
        "\n",
        "Next up on our list is **Hadamard product**, also called element-wise multiplication.\n",
        "\n",
        "To perform the Hadamard product, our vectors/matrices must be of the exact same size, just like with addition and subtraction.\n",
        "\n",
        "Since the Hadamard product is just element-wise multiplication, you just have to multiply the corresponding components of the vectors/matrices!\n",
        "\n",
        "So, for vectors:\n",
        "\n",
        "$$ \\vec{a} \\circ \\vec{b} = \\begin{bmatrix}a_xb_x\\\\a_yb_y\\\\a_zb_z\\end{bmatrix}$$\n",
        "\n",
        "And for matrices:\n",
        "\n",
        "$$\\mathbf{A} \\circ \\mathbf{B} = \\begin{bmatrix}A_{11}B_{11} & A_{12}B_{12}\\\\ A_{21}B_{21} & A_{22}B_{22}\\end{bmatrix}$$\n",
        "\n",
        "Third is the **dot product**!\n",
        "\n",
        "The dot product is performed between two vectors and is pretty much the sum of all the components in the Hadamard product.\n",
        "\n",
        "The dot product is also commutative, so $\\vec{a}\\cdot\\vec{b} = \\vec{b}\\cdot\\vec{a}$\n",
        "\n",
        "So:\n",
        "\n",
        "$$ \\vec{a} \\cdot \\vec{b} = a_xb_x + a_yb_y + a_zb_z$$\n",
        "\n",
        "For a pair of vectors with length n:\n",
        "\n",
        "$$ \\vec{a} \\cdot \\vec{b} = \\sum_{i=1}^n a_ib_i$$\n",
        "\n",
        "Geometrically, the dot product can be interpreted as the projection of one vector onto another and is the basis for a type of similarity measurement called cosine similarity.\n",
        "\n",
        "<img src=\"https://i.ibb.co/qFh0RHM/dotproduct.png\" alt=\"dotproduct\" border=\"0\">\n",
        "\n",
        "Next would be the **cross product**, but it's pretty much irrelevant to machine learning, so I'll just put a link to the wikipedia page. It also takes a horrendously long time to explain, so there's that too.\n",
        "\n",
        "https://en.wikipedia.org/wiki/Cross_product\n",
        "\n",
        "Last, but probably one of the most important, **matrix multiplication**!\n",
        "\n",
        "To multiply matrices, they must be of a very specific shape.\n",
        "\n",
        "If the first matrix is of shape $m \\times n$, then the second shape must be $n \\times p$ where $p$ is an arbitrary number. The resulting matrix will then be of shape $m \\times p$.\n",
        "\n",
        "So, I've always found matrix multiplications really strange to describe, but I imagine them as a set of dot products between the rows and columns of a matrix.\n",
        "\n",
        "We can walk through it at this link: http://matrixmultiplication.xyz/\n",
        "\n",
        "It is important to note that matrix multiplications are NOT commutative.\n",
        "\n",
        "Matrix multiplication has several important uses in Machine Learning.\n",
        "\n",
        "First of all, it represents linear transformations.\n",
        "\n",
        "When we do a matrix multiplication between a matrix and an appropriately-dimensioned vector (because vectors can be viewed as matrices, too), we apply a combination of stretching, squeezing, rotating, shearing, and reflecting (as well as the occasional orthogonal projection).\n",
        "\n",
        "Here's a good example:\n",
        "\n",
        "<img src=\"https://i.ibb.co/72wv75M/matrixtransformation.gif\" alt=\"matrixtransformation\" border=\"0\">\n",
        "\n",
        "In this example, we are demonstrating a combination of a rotation and a shear transformation.\n",
        "\n",
        "Secondly, and probably more importantly, it represents a linear system of equations.\n",
        "\n",
        "\n",
        "Example:\n",
        "$$ \\mathbf{A}\\vec{v} = \\vec{c}$$\n",
        "\n",
        "If $\\mathbf{A} = \\begin{bmatrix}1 & 2 \\\\ 3 & 4 \\end{bmatrix}$, $\\vec{v} = \\begin{bmatrix}x \\\\ y \\end{bmatrix}$ and $\\vec{c} = \\begin{bmatrix}1 \\\\ 2\\end{bmatrix}$, then:\n",
        "\n",
        "$$\\mathbf{A}\\vec{v} = \\begin{bmatrix}1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\begin{bmatrix}x \\\\ y \\end{bmatrix} = \\begin{bmatrix}1x+2y\\\\3x+4y\\end{bmatrix} = \\begin{bmatrix}1 \\\\ 2\\end{bmatrix} = \\vec{c}$$\n",
        "\n",
        "This is equivalent to this linear system of equations:\n",
        "\n",
        "$$1x+2y=1$$\n",
        "$$3x+4y=2$$\n",
        "\n",
        "Using matrix multiplication, we can accelerate numerous tasks!\n",
        "\n",
        "##### MiniQuiz\n",
        "\n",
        "1. Can you give me the dot product of these two vectors: $\\begin{bmatrix}1\\\\2\\\\3\\end{bmatrix}$ and $\\begin{bmatrix}-2\\\\3\\\\5\\end{bmatrix}$?\n",
        "<br/>\n",
        "<br/>\n",
        "2. How about the scalar product of this scalar and this vector: $3$ and $\\begin{bmatrix}-2\\\\3\\\\5\\end{bmatrix}$?\n",
        "3. Ooh, what about the matrix multiplication of this row vector and this column vector: $\\begin{bmatrix}-2 & 3 & 5\\end{bmatrix}$ and $\\begin{bmatrix}-2\\\\3\\\\5\\end{bmatrix}$?\n",
        "\n",
        "\n",
        "#### Division\n",
        "\n",
        "Sadly, outside of scalar division (which is really just multiplication by the reciprocal), division isn't actually a real thing with matrices and vectors. However, closely related is matrix inversion, which is likely out of the scope of an \"Introduction to Matrices and Vectors\"\n",
        "\n",
        "#### Transpose\n",
        "\n",
        "Not only do vectors and matrices have arithmetic operations, they also have a whole boatload of other operations! But for this intro, we'll just discuss transposes.\n",
        "\n",
        "Transposes allow you to \"flip\" the matrix/vector over its main diagonal.\n",
        "\n",
        "For row vectors, their corresponding column vector is its transpose (and vice versa).\n",
        "\n",
        "For example:\n",
        "\n",
        "This column vector, $\\begin{bmatrix}-2\\\\3\\\\5\\end{bmatrix}$ is the transpose of this row vector $\\begin{bmatrix}-2 & 3 & 5\\end{bmatrix}$.\n",
        "\n",
        "When you take the transpose of a matrix (and vector) of shape $(m \\times n)$, the resultant matrix/vector will have shape  $(n \\times m)$.\n",
        "\n",
        "Example:\n",
        "\n",
        "$$\\mathbf{A} = \\begin{bmatrix} A_{11} & A_{12} & A_{13}\\\\ A_{21} & A_{22} & A_{23}\\end{bmatrix}$$\n",
        "<br/>\n",
        "<br/>\n",
        "$$\\mathbf{A}^\\top = \\begin{bmatrix} A_{11} & A_{21} \\\\ A_{12} & A_{22}\\\\ A_{13} & A_{23}\\end{bmatrix}$$\n",
        "\n",
        "### Codifying it all!\n",
        "\n",
        "Now that we've covered all these ways to do arithmetics, let's do them in Python!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkKS-MbzuBUV"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create some random scalars, vectors and matrices\n",
        "\n",
        "l = np.random.randint(2, 5)\n",
        "\n",
        "a = np.random.randint(-10, 10, size=(3, 1))\n",
        "b = np.random.randint(-10, 10, size=(3, 1))\n",
        "\n",
        "A = np.random.randint(-5, 5, size=(3, 3))\n",
        "B = np.random.randint(-5, 5, size=(3, 3))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0f13-pnuBUZ",
        "outputId": "ffceca7b-c5b0-49e8-8301-3178a24b1fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Addition\n",
        "\n",
        "c = a + b\n",
        "\n",
        "print(\"Vector a\")\n",
        "print(a)\n",
        "print(\"Vector b\")\n",
        "print(b)\n",
        "print(\"Vector c\")\n",
        "print(c)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector a\n",
            "[[-1]\n",
            " [-7]\n",
            " [-4]]\n",
            "Vector b\n",
            "[[-4]\n",
            " [-6]\n",
            " [-8]]\n",
            "Vector c\n",
            "[[ -5]\n",
            " [-13]\n",
            " [-12]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_L2_hueuBUc",
        "outputId": "004ecdbd-1f25-4002-dbfb-eb4da9959c69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Subtraction\n",
        "\n",
        "d = c - a # You should expect b because c = a + b\n",
        "\n",
        "print(\"Vector c\")\n",
        "print(c)\n",
        "print(\"Vector a\")\n",
        "print(a)\n",
        "print(\"Vector d\")\n",
        "print(d)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector c\n",
            "[[ -5]\n",
            " [-13]\n",
            " [-12]]\n",
            "Vector a\n",
            "[[-1]\n",
            " [-7]\n",
            " [-4]]\n",
            "Vector d\n",
            "[[-4]\n",
            " [-6]\n",
            " [-8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ziK2eDhuBUf",
        "outputId": "9f39b939-a699-453d-a4c8-34369ef5fcb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Scalar Multiplication\n",
        "\n",
        "e = l * a  # Scaling vector a by the scalar l\n",
        "\n",
        "print(\"Scalar l\")\n",
        "print(l)\n",
        "print(\"Vector a\")\n",
        "print(a)\n",
        "print(\"Vector e\")\n",
        "print(e)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scalar l\n",
            "2\n",
            "Vector a\n",
            "[[-1]\n",
            " [-7]\n",
            " [-4]]\n",
            "Vector e\n",
            "[[ -2]\n",
            " [-14]\n",
            " [ -8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt78da1K32MC",
        "outputId": "5239670e-fd76-47e8-a7a2-3490b7430d3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Hadamard Multiplication\n",
        "\n",
        "C = A * B\n",
        "\n",
        "print(\"Matrix A\")\n",
        "print(A)\n",
        "print(\"Matrix B\")\n",
        "print(B)\n",
        "print(\"Matrix C\")\n",
        "print(C)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  0 -5]\n",
            " [ 2  2 -3]\n",
            " [-5 -3 -1]]\n",
            "[[-4  1  0]\n",
            " [ 3  4 -3]\n",
            " [-4 -2  2]]\n",
            "[[-4  0  0]\n",
            " [ 6  8  9]\n",
            " [20  6 -2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw29LkITuBUh",
        "outputId": "bce50479-d6d4-4501-b8b5-06d0cc50aae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Dot Product\n",
        "\n",
        "# In NumPy we can use np.dot or ndarray.dot to perform dot products, however, it expects 1-D row vectors.\n",
        "\n",
        "# To get the row vectors from the column vectors, we can squeeze (remove dimensions with length 1)\n",
        "\n",
        "\n",
        "c = np.dot(a.squeeze(1), b.squeeze(1))\n",
        "\n",
        "print(\"Vector a\")\n",
        "print(a)\n",
        "print(\"Vector b\")\n",
        "print(b)\n",
        "print(\"Vector c\")\n",
        "print(c)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector a\n",
            "[[-1]\n",
            " [-7]\n",
            " [-4]]\n",
            "Vector b\n",
            "[[-4]\n",
            " [-6]\n",
            " [-8]]\n",
            "Vector c\n",
            "78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOy-6ljduBUj",
        "outputId": "4d22644d-8d55-4633-c9bb-d0694d8f3557",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Matrix Multiplication\n",
        "\n",
        "# Matrix-Matrix\n",
        "\n",
        "# NumPy provides the \"@\" operator for matrix multiplication.\n",
        "\n",
        "C = A @ B\n",
        "\n",
        "print(\"Matrix A\")\n",
        "print(A)\n",
        "print(\"Matrix B\")\n",
        "print(B)\n",
        "print(\"Matrix C\")\n",
        "print(C)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix A\n",
            "[[ 1  0 -5]\n",
            " [ 2  2 -3]\n",
            " [-5 -3 -1]]\n",
            "Matrix B\n",
            "[[-4  1  0]\n",
            " [ 3  4 -3]\n",
            " [-4 -2  2]]\n",
            "Matrix C\n",
            "[[ 16  11 -10]\n",
            " [ 10  16 -12]\n",
            " [ 15 -15   7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O1q0q-GuBUm",
        "outputId": "ec5bde11-0b7c-4fc1-fa45-b40fb96d771e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Matrix-Vector\n",
        "\n",
        "c = A @ b\n",
        "\n",
        "print(\"Matrix A\")\n",
        "print(A)\n",
        "print(\"Vector b\")\n",
        "print(b)\n",
        "print(\"Vector c\")\n",
        "print(c)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix A\n",
            "[[ 1  0 -5]\n",
            " [ 2  2 -3]\n",
            " [-5 -3 -1]]\n",
            "Vector b\n",
            "[[-4]\n",
            " [-6]\n",
            " [-8]]\n",
            "Vector c\n",
            "[[36]\n",
            " [ 4]\n",
            " [46]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxSj_JswuBUp",
        "outputId": "b4cb8cf7-387a-49c9-feed-45ff70fca177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Vector-Vector\n",
        "\n",
        "# Our vectors have shape (3 x 1) so they can't normally multiply.\n",
        "# However, if you \"transpose\" the first vector, you get shape (1 x 3), so you can multiply.\n",
        "\n",
        "# To transpose, NumPy has the ndarray.T attribute\n",
        "\n",
        "c = a.T @ b\n",
        "\n",
        "print(\"Vector A\")\n",
        "print(a.T)\n",
        "print(\"Vector B\")\n",
        "print(b)\n",
        "print(\"Matrix C\")\n",
        "print(c) # Technically it's not a scalar, but a (1 x 1) matrix, but it's practically a scalar.\n",
        "\n",
        "# If you notice, this is equivalent to the dot product of a and b."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector A\n",
            "[[-1 -7 -4]]\n",
            "Vector B\n",
            "[[-4]\n",
            " [-6]\n",
            " [-8]]\n",
            "Matrix C\n",
            "[[78]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lTJIcBMuBUr",
        "outputId": "49893de9-d216-4a87-c3de-103fc63cdfcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Transpose\n",
        "\n",
        "# Let's do some more transpose demonstrations!\n",
        "\n",
        "A = np.random.randint(0, 5, size=(3, 3))\n",
        "\n",
        "print(\"Matrix A\")\n",
        "print(A)\n",
        "print(\"Matrix A Transpose\")\n",
        "print(A.T)\n",
        "\n",
        "B = np.random.randint(0, 5, size=(3, 4))\n",
        "\n",
        "print(\"Matrix B\")\n",
        "print(B)\n",
        "print(\"Matrix B Transpose\")\n",
        "print(B.T)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix A\n",
            "[[2 3 1]\n",
            " [1 4 2]\n",
            " [3 1 3]]\n",
            "Matrix A Transpose\n",
            "[[2 1 3]\n",
            " [3 4 1]\n",
            " [1 2 3]]\n",
            "Matrix B\n",
            "[[1 2 4 3]\n",
            " [4 1 2 1]\n",
            " [0 1 3 4]]\n",
            "Matrix B Transpose\n",
            "[[1 4 0]\n",
            " [2 1 1]\n",
            " [4 2 3]\n",
            " [3 1 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}